{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2IsRmtZtfGL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Create a random tensor of shape (4, 6)\n",
        "tensor = tf.random.uniform(shape=(4, 6), minval=0, maxval=10, dtype=tf.float32)\n",
        "\n",
        "# Step 2: Find rank and shape\n",
        "rank = tf.rank(tensor)\n",
        "shape = tf.shape(tensor)\n",
        "\n",
        "# Step 3: Reshape to (2, 3, 4) and transpose to (3, 2, 4)\n",
        "reshaped_tensor = tf.reshape(tensor, (2, 3, 4))\n",
        "transposed_tensor = tf.transpose(reshaped_tensor, perm=[1, 0, 2])\n",
        "\n",
        "# Step 4: Broadcasting and Addition (Fixed)\n",
        "small_tensor = tf.random.uniform(shape=(1, 6), minval=0, maxval=10, dtype=tf.float32)  # (1,6) is broadcastable\n",
        "broadcasted_tensor = tf.broadcast_to(small_tensor, shape=(4, 6))  # Now it works\n",
        "result_tensor = tensor + broadcasted_tensor\n",
        "\n",
        "# Step 5: Broadcasting Explanation\n",
        "broadcasting_explanation = \"\"\"\n",
        "Broadcasting in TensorFlow allows smaller tensors to expand to match the shape of larger tensors without creating unnecessary copies.\n",
        "It follows NumPy broadcasting rules:\n",
        "1. If the dimensions are equal, they are compatible.\n",
        "2. If one tensor has a size of 1 in a dimension, it gets expanded to match the other tensor.\n",
        "3. If neither condition is met, TensorFlow raises an error.\n",
        "\n",
        "In this case, (1,6) can be broadcast to (4,6) because the first dimension is 1, so it expands to match the larger tensor.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Tensor Shape:\", tensor.shape)\n",
        "print(\"Tensor Rank:\", rank.numpy())\n",
        "print(\"Reshaped Tensor Shape:\", reshaped_tensor.shape)\n",
        "print(\"Transposed Tensor Shape:\", transposed_tensor.shape)\n",
        "print(\"Broadcasted Tensor Shape:\", broadcasted_tensor.shape)\n",
        "print(\"Final Result Shape:\", result_tensor.shape)\n",
        "print(\"Broadcasting Explanation:\", broadcasting_explanation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAhc65NsuW8R",
        "outputId": "c055ed2d-f211-43b6-8ea4-93b929a99e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor Shape: (4, 6)\n",
            "Tensor Rank: 2\n",
            "Reshaped Tensor Shape: (2, 3, 4)\n",
            "Transposed Tensor Shape: (3, 2, 4)\n",
            "Broadcasted Tensor Shape: (4, 6)\n",
            "Final Result Shape: (4, 6)\n",
            "Broadcasting Explanation: \n",
            "Broadcasting in TensorFlow allows smaller tensors to expand to match the shape of larger tensors without creating unnecessary copies.\n",
            "It follows NumPy broadcasting rules:\n",
            "1. If the dimensions are equal, they are compatible.\n",
            "2. If one tensor has a size of 1 in a dimension, it gets expanded to match the other tensor.\n",
            "3. If neither condition is met, TensorFlow raises an error.\n",
            "\n",
            "In this case, (1,6) can be broadcast to (4,6) because the first dimension is 1, so it expands to match the larger tensor.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
